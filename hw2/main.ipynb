{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tema 2 - Perceptron <br>\n",
    "Ne propunem sa cream un model capabil sa recunoasca imagini alb-negru cu cifre scrise de mana.<br>"
   ],
   "id": "4c89c23651f05293"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Initializarea datelor<br>\n",
    "Folosim dataset-ul MNIST pentru antrenarea si testarea modelului."
   ],
   "id": "4bf3eb5e8397a06e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T20:16:52.082019Z",
     "start_time": "2024-10-20T20:16:33.863516Z"
    }
   },
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from numpy.ma.core import reshape\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "def download_mnist(is_train: bool):\n",
    "    dataset = MNIST(root='./data',\n",
    "    transform=lambda x: np.array(x).flatten(),\n",
    "    download=True,\n",
    "    train=is_train)\n",
    "    mnist_data = []\n",
    "    mnist_labels = []\n",
    "    for image, label in dataset:\n",
    "        mnist_data.append(image)\n",
    "        mnist_labels.append(label)\n",
    "    return mnist_data, mnist_labels"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:17:08.852970Z",
     "start_time": "2024-10-20T20:17:08.842964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_data() -> (np.array, np.array, np.array, np.array):\n",
    "    train_x, train_y = download_mnist(True)\n",
    "    test_x, test_y = download_mnist(False)\n",
    "    \n",
    "    #convertim datele in np.array s\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y\n",
    "    "
   ],
   "id": "19d790b2e5f1af7c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalizarea setului de date + one-hot encoding<br>\n",
    "Valorile din seturile de date sunt numere intregi cuprinse in intervalul $[0, 256]$. Pentru a normaliza datele, vom imparti la 256, aducand valorile in intervalul $[0. 1]$. <br>\n",
    "<br>\n",
    "Q: De ce ajuta sa normalizam setul?<br>\n",
    "Cred ca mi-am raspuns singur la intrebare; numerele ajung foarte mari daca nu facem asta."
   ],
   "id": "48897dbedb0ab5ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:17:12.438047Z",
     "start_time": "2024-10-20T20:17:12.432096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_data(v: np.array) -> np.array:\n",
    "    return v / 256"
   ],
   "id": "cdd05b83783c4989",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:17:13.829612Z",
     "start_time": "2024-10-20T20:17:13.814608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot_encode(v: np.array, nr_classes: int) -> np.array:\n",
    "    return np.array([np.array([int(i == label) for i in range(nr_classes)]) for label in v])\n",
    "# test_Y = np.array([np.array([int(i == label) for i in range(10)]) for label in test_Y]) #sa nu mai uit niciodata sa fac encoding si la test labels"
   ],
   "id": "bf5802fc2ae1ca62",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Forward propagation<br>\n",
    "Utilizam functia softmax pentru a crea un output balansat. Deoarece functia foloseste exponentiere, diferentele dintre valorile claselor dupa inmultirea cu ponderile vor avea un impact mult mai mare asupra probabilitatii rezultate.<br>\n",
    "De asemenea asigura proprietatea de aditivitate numarabila a outputului (aka suma probabilitatilor este 1).\n"
   ],
   "id": "d49b3b1897486c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:17:15.840280Z",
     "start_time": "2024-10-20T20:17:15.821367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "def softmax(z: np.array) -> np.array:\n",
    "    exp_sum = sum([math.e**element for element in z])\n",
    "    return np.array([math.e**element / exp_sum for element in z])\n",
    "\n",
    "def make_prediction(weights: np.array, bias: np.array, instance: np.array) -> np.array:\n",
    "    #z = np.dot(weights, instance) + bias\n",
    "    z = [np.dot(weights[i], instance) + bias[i] for i in range(len(weights))]\n",
    "    return softmax(z)\n",
    "    "
   ],
   "id": "211fe217d3d8162b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Antrenarea intr-o epoca\n",
    "\n",
    "folosim modelul pentru a face o predictie asupra instantelor de testare. Calculam eroarea comparand rezultatul obtinut cu label-ul real al instantei si ponderam aceasta eroare cu coeficientul de invatare si array-ul actual de greutati (weights). Cumulam aceaste eroari ponderate intr-un array cu acelasi shape ca si weights pentru a face update ulterior. Procedam asemanator si pentru bias."
   ],
   "id": "dcb225e6346b2d25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:17:17.895277Z",
     "start_time": "2024-10-20T20:17:17.880317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(x: np.array, y: np.array, weights: np.ndarray, bias: np.ndarray, alpha: float) -> (np.array, np.array):\n",
    "    delta = np.zeros_like(weights)\n",
    "    beta = np.zeros_like(bias)\n",
    "    for i in range(len(x)):\n",
    "        predicted_y = make_prediction(weights, bias, x[i])\n",
    "        error =  (y[i] - predicted_y)\n",
    "        delta = delta + alpha * np.dot(error.reshape(len(predicted_y), 1), np.atleast_2d(x[i]))\n",
    "        #delta = delta + alpha * error.reshape(len(predicted_y), 1) * np.tile(x[i], (len(weights), 1))\n",
    "        beta = beta + alpha * error\n",
    "    return delta, beta"
   ],
   "id": "508463885c0f537f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Simularea epocilor si initializarea parametrilor<br>\n",
    "Pentru un numar predefinit de epoci antrenam modelul pe training set. Intr-o epoca dam shuffle la setul de date, il impartim in batch-uri, calculam update-ul per batch si facem update la weights si bias de la batch la batch (un fel de mini batch training?).<br>\n",
    "<br>\n",
    "Q: De ce facem batches daca algoritmul nu poate fi paralelizat?"
   ],
   "id": "f772d86ae617b1a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:17:20.466462Z",
     "start_time": "2024-10-20T20:17:20.452448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_model(weights: np.array, bias: np.array, x: np.array, y: np.array, alpha: float, epochs: int, batch_size: int) -> None:\n",
    "    delta = np.zeros_like(weights)\n",
    "    beta = np.zeros_like(bias)\n",
    "    while epochs > 0:\n",
    "        perm = np.random.permutation(len(x))\n",
    "        x = x[perm]\n",
    "        y = y[perm]\n",
    "        for i in range(len(x) // batch_size):\n",
    "            delta1, beta1 = train(x[i * batch_size : (i + 1) * batch_size], y[i * batch_size : (i + 1) * batch_size], weights, bias, alpha)\n",
    "            # delta += delta1\n",
    "            # beta += beta1\n",
    "            weights += delta1\n",
    "            bias += beta1\n",
    "        epochs -= 1"
   ],
   "id": "607b96df9ab6c8b2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initializam weight-urile si bias-ul cu valori random pe care le normalizam.",
   "id": "c0c06833c3506bf0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:17:22.954040Z",
     "start_time": "2024-10-20T20:17:22.942070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def random_init_model() -> (np.array, np.array):\n",
    "    w = np.random.randn(10, 784)\n",
    "    b = np.random.randn(10)\n",
    "    \n",
    "    #normalize\n",
    "    w = (w - w.min()) / (w.max() - w.min())\n",
    "    b = (b - b.min()) / (b.max() - b.min())\n",
    "    \n",
    "    #scale\n",
    "    w = 2 * w - 1\n",
    "    b = 2 * b - 1\n",
    "    \n",
    "    return w, b"
   ],
   "id": "58e3e72c0c8581",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:17:24.720301Z",
     "start_time": "2024-10-20T20:17:24.709351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#se calculeaza acuratetea unui model dat fiind un set de date\n",
    "def assert_accuracy(weights: np.array, bias: np.array, test_x: np.array, test_y: np.array) -> float:\n",
    "    nr_successes = 0\n",
    "    for i in range(len(test_x)):\n",
    "        predicted_y = make_prediction(weights, bias, test_x[i])\n",
    "        if predicted_y.argmax() == test_y[i].argmax():\n",
    "            nr_successes += 1\n",
    "    return nr_successes / len(test_x)"
   ],
   "id": "9fd7a0be1f32403",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T21:26:25.089416Z",
     "start_time": "2024-10-19T21:26:24.843200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #verificam acuratetea modelului initializat aleator\n",
    "# #ar trebui sa fie ~0.1\n",
    "# random_init_acc = assert_accuracy(w, b, test_X, test_Y)\n",
    "# print(random_init_acc)"
   ],
   "id": "9669863f7013611",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1253\n"
     ]
    }
   ],
   "execution_count": 497
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T21:32:57.645927Z",
     "start_time": "2024-10-19T21:31:58.089066Z"
    }
   },
   "cell_type": "code",
   "source": "# make_model(w, b, train_X, train_Y, alpha=0.001, epochs=20, batch_size=100)",
   "id": "cbab263bff47c05a",
   "outputs": [],
   "execution_count": 503
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T21:34:28.950710Z",
     "start_time": "2024-10-19T21:34:28.637103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #verificam acuratetea modelului antrenat\n",
    "# model_acc = assert_accuracy(w, b, test_X, test_Y)\n",
    "# print(model_acc)"
   ],
   "id": "fb48cf8d01109f02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8956\n"
     ]
    }
   ],
   "execution_count": 504
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:57:55.174278Z",
     "start_time": "2024-10-20T20:57:55.159316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "params_list = [\n",
    "    {\"Epochs\": 1, \"Learning Rate\": 0.1},\n",
    "    {\"Epochs\": 1, \"Learning Rate\": 0.01},\n",
    "    {\"Epochs\": 10, \"Learning Rate\": 0.1},\n",
    "    {\"Epochs\": 10, \"Learning Rate\": 0.01},\n",
    "    {\"Epochs\": 20, \"Learning Rate\": 0.1},\n",
    "    {\"Epochs\": 20, \"Learning Rate\": 0.01},\n",
    "    # {\"Epochs\": 100, \"Learning Rate\": 0.1},\n",
    "    # {\"Epochs\": 100, \"Learning Rate\": 0.01},\n",
    "]"
   ],
   "id": "6db304139d703400",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T21:28:58.045789Z",
     "start_time": "2024-10-20T20:57:57.496670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "train_X, train_Y, test_X, test_Y = initialize_data()\n",
    "\n",
    "train_X = normalize_data(train_X)\n",
    "test_X = normalize_data(test_X)\n",
    "\n",
    "train_Y = one_hot_encode(train_Y, nr_classes = 10)\n",
    "test_Y = one_hot_encode(test_Y, nr_classes = 10)\n",
    "\n",
    "nr_tests_per_param = 10\n",
    "\n",
    "results = []\n",
    "for params in params_list:\n",
    "    for _ in range(nr_tests_per_param):\n",
    "        w, b = random_init_model()\n",
    "        \n",
    "        start = time.time()\n",
    "        make_model(w, b, train_X, train_Y, alpha=params[\"Learning Rate\"], epochs=params[\"Epochs\"], batch_size=100)\n",
    "        end = time.time()\n",
    "        \n",
    "        results.append({\"Epochs\": params[\"Epochs\"], \"Learning Rate\": params[\"Learning Rate\"], \"Training Time\": end - start, \"Accuracy\": assert_accuracy(w, b, test_X, test_Y)})"
   ],
   "id": "d6f35de509b2c7df",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:23:25.460203Z",
     "start_time": "2024-10-20T20:22:54.762603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w, b = random_init_model()\n",
    "make_model(w, b, train_X, train_Y, alpha=0.1, epochs=10, batch_size=100)"
   ],
   "id": "9fcf845d41baaa97",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:24:01.287223Z",
     "start_time": "2024-10-20T20:24:00.936136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_acc = assert_accuracy(w, b, test_X, test_Y)\n",
    "print(model_acc)"
   ],
   "id": "7ae84391ef54c969",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9037\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rezultate",
   "id": "385d14b8bd4b2a59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"model_training_results.csv\", index=False)"
   ],
   "id": "30a8cdae04124173"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T21:50:12.378359Z",
     "start_time": "2024-10-20T21:50:12.352011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "averaged_results = df.groupby([\"Epochs\", \"Learning Rate\"]).agg({\n",
    "    \"Accuracy\": \"mean\",\n",
    "    \"Training Time\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "print(averaged_results)"
   ],
   "id": "1eff29a1d457f64c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epochs  Learning Rate  Accuracy  Training Time\n",
      "0       1           0.01   0.90353       2.993196\n",
      "1       1           0.10   0.86499       2.996382\n",
      "2      10           0.01   0.91687      30.360469\n",
      "3      10           0.10   0.88158      29.725730\n",
      "4      20           0.01   0.91976      59.127596\n",
      "5      20           0.10   0.88567      58.794753\n"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
